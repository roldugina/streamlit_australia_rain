{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f23e055-9dcf-44d3-9894-ec71b901cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "from load_and_preprocess import load_model_components, preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "506fea0d-e585-4ba2-aba2-a47740371d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_components = load_model_components('models/aussie_rain.joblib')\n",
    "#joblib.dump(model, 'models/aussie_rain.joblib', compress=('zlib', 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa44570-62d3-4a5c-8f32-aeba480f0abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('data/weatherAUS.csv')\n",
    "raw_df.dropna(subset=['RainToday', 'RainTomorrow'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4415d113-b0f8-4db2-9f15-25e8a56345d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_df[model_components['input_cols']]\n",
    "y = raw_df[model_components['target_col']]\n",
    "train_inputs, test_inputs, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b51ae6a5-eee6-44f7-9303-a2f8a9de6eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location          0.00%\n",
       "MinTemp           0.32%\n",
       "MaxTemp           0.20%\n",
       "Rainfall          0.00%\n",
       "Evaporation      42.45%\n",
       "Sunshine         47.55%\n",
       "WindGustDir       6.51%\n",
       "WindGustSpeed     6.47%\n",
       "WindDir9am        6.85%\n",
       "WindDir3pm        2.60%\n",
       "WindSpeed9am      0.74%\n",
       "WindSpeed3pm      1.79%\n",
       "Humidity9am       1.07%\n",
       "Humidity3pm       2.50%\n",
       "Pressure9am       9.80%\n",
       "Pressure3pm       9.83%\n",
       "Cloud9am         37.38%\n",
       "Cloud3pm         39.84%\n",
       "Temp9am           0.45%\n",
       "Temp3pm           1.87%\n",
       "RainToday         0.00%\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.isna().sum().apply(lambda x: format(x/train_inputs.shape[0],'.2%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "643a10b1-246d-4190-8541-d7286470e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'Imputer type: {type(imputer)}, \\n\\n'\n",
    "#      f'Imputer features: {imputer.feature_names_in_}, \\n\\n'\n",
    "#      f'Imputer strategy: {imputer.strategy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0c6df53-69d7-49ba-8d9d-8bbbadeed480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n",
      "C:\\study\\07_ML_course\\tasks\\streamlit\\load_and_preprocess.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[components['encoded_cols']] = components['encoder'].transform(data[components['categorical_cols']])\n"
     ]
    }
   ],
   "source": [
    "X_train, train_inputs = preprocess_data(train_inputs, model_components)\n",
    "X_test, test_inputs = preprocess_data(test_inputs, model_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a33846fe-465c-44cb-b8be-4da01241cdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No     0.8333    0.9811    0.9012     87668\n",
      "         Yes     0.8242    0.3109    0.4515     24961\n",
      "\n",
      "    accuracy                         0.8326    112629\n",
      "   macro avg     0.8288    0.6460    0.6763    112629\n",
      "weighted avg     0.8313    0.8326    0.8015    112629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=40, max_leaf_nodes=30, n_jobs=-1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "pred_train = model.predict(X_train)\n",
    "print(classification_report(y_train, pred_train, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b8bf281-390b-40fd-86bf-02895fe667de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No     0.8344    0.9798    0.9013     21918\n",
      "         Yes     0.8171    0.3171    0.4569      6240\n",
      "\n",
      "    accuracy                         0.8329     28158\n",
      "   macro avg     0.8258    0.6485    0.6791     28158\n",
      "weighted avg     0.8306    0.8329    0.8028     28158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(X_test)\n",
    "print(classification_report(y_test, pred_test, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05bd2d24-03db-43e2-931e-cbd868755141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/rf_model.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = {\n",
    "    'model': model_components['model'],\n",
    "    'imputer': model_components['imputer'],\n",
    "    'scaler': model_components['scaler'],\n",
    "    'encoder': model_components['encoder'],\n",
    "    'input_cols': model_components['input_cols'],\n",
    "    'target_col': model_components['target_col'],\n",
    "    'numeric_cols': model_components['numeric_cols'],\n",
    "    'categorical_cols': model_components['categorical_cols'],\n",
    "    'encoded_cols': model_components['encoded_cols']\n",
    "}\n",
    "joblib.dump(rf_model, \"models/rf_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f3e4a1-e172-4215-aa29-b5107d15c562",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (streamlit_env)",
   "language": "python",
   "name": "streamlit_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
